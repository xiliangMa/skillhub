# GitHub爬虫系统设计文档

## 文档信息
- **创建日期**: 2026-01-31
- **项目**: Skills商店SaaS平台
- **组件**: GitHub爬虫服务
- **状态**: 已实现

## 设计决策

### 1. 爬取范围
**决策**: 仅爬取GitHub仓库元数据
**理由**:
- 用户明确要求仅获取仓库基本信息
- 避免复杂的SKILL.md解析逻辑
- 减少API调用和数据存储复杂性

### 2. 同步策略
**决策**: 智能同步（混合策略）
**实现**:
- 首次运行: 全量同步所有配置主题的仓库
- 后续运行: 增量同步（基于`last_sync_at`时间戳）
- 定期刷新: 每周一执行全量刷新以更新stars/forks统计

### 3. API访问方式
**决策**: GitHub Token认证
**优势**:
- 提高API速率限制（5000次/小时 vs 60次/小时）
- 支持更频繁的数据同步
- 更好的API稳定性

### 4. 仓库过滤策略
**决策**: 按标签/主题过滤
**配置**: 通过环境变量`GITHUB_TOPICS`配置主题列表
**默认主题**: `ai,automation,developer-tools,machine-learning`

## 系统架构

### 组件设计

#### 1. GitHub客户端 (`github_client.go`)
- 封装go-github/v58库
- 支持Token认证和匿名访问
- 提供仓库搜索和详情获取接口
- 实现GitHub仓库到技能模型的转换

#### 2. 智能同步引擎 (`sync_engine.go`)
- 策略模式支持全量/增量/智能同步
- 增量同步基于仓库更新时间戳
- 自动检测首次运行和定期刷新需求
- 完善的错误处理和重试机制

#### 3. 配置管理 (`config.go`扩展)
- 新增GitHub配置字段:
  - `Topics`: 主题列表
  - `SyncStrategy`: 同步策略
  - `SyncInterval`: 同步间隔
  - `PerPage`: 分页大小
  - `MaxPages`: 最大页数

#### 4. 主调度器 (`crawler.go`)
- 集成同步引擎
- 提供定时任务接口
- 数据库连接管理

### 数据模型修改

#### Skill模型扩展
1. **新增字段**:
   - `SyncSource`: 同步来源（默认'manual'）
   - 保留现有`LastSyncAt`字段用于同步时间戳

#### SyncLog模型使用
- 复用现有的`SyncLog`数据模型
- 记录同步任务状态和统计信息

### 数据库集成

#### 数据存储策略
1. **去重机制**: 基于`github_url`字段识别重复仓库
2. **更新策略**: 仅更新变化字段（stars、forks、描述等）
3. **关系处理**: 暂不处理分类和标签关系，保持简单性

### 定时任务集成

#### 调度器配置
- 启用`scheduler.go`中的爬虫调用
- 默认每日凌晨3点执行同步
- 支持数据库配置的定时任务

## 配置要求

### 环境变量
```bash
# 必需
GITHUB_TOKEN=your_personal_access_token

# 可选（有默认值）
GITHUB_TOPICS=ai,automation,developer-tools,machine-learning
GITHUB_SYNC_STRATEGY=smart  # full|incremental|smart
GITHUB_SYNC_INTERVAL=3600   # 同步间隔（秒）
GITHUB_PER_PAGE=30          # 每页结果数
GITHUB_MAX_PAGES=10         # 最大页数
```

### 依赖项
```go
github.com/google/go-github/v58 v58.0.0
```

## 实施细节

### 关键实现要点

1. **速率限制处理**
   - 监控API剩余调用次数
   - 剩余次数低于阈值时自动等待
   - 避免触发GitHub API限制

2. **错误恢复**
   - 单个主题失败不影响其他主题
   - 单个仓库保存失败记录日志继续处理
   - 网络错误自动重试（通过上层调度器）

3. **性能优化**
   - 增量同步减少API调用
   - 批量处理分页结果
   - 合理的默认分页大小

### 代码结构
```
backend/services/crawler/
├── crawler.go          # 主入口和调度接口
├── github_client.go    # GitHub API客户端
├── sync_engine.go      # 智能同步引擎
└── (未来可扩展)
    ├── topic_config.go # 主题配置管理
    └── data_processor.go # 数据后处理
```

## 测试计划

### 单元测试（待实现）
1. **GitHub客户端测试**
   - 认证配置验证
   - API调用模拟
   - 数据转换逻辑

2. **同步引擎测试**
   - 策略选择逻辑
   - 增量/全量同步判断
   - 错误处理流程

### 集成测试（待实现）
1. **端到端流程测试**
   - 完整的同步流程
   - 数据库存储验证
   - 定时任务触发

2. **API集成测试**
   - 实际GitHub API调用
   - 速率限制验证
   - 网络错误处理

## 监控和日志

### 日志记录
- 同步开始/结束时间
- 处理的仓库数量
- 错误详情和恢复情况
- API速率限制状态

### 监控指标（未来扩展）
- 同步成功率
- 平均处理时间
- API调用次数统计
- 数据更新频率

## 已知限制

### 技术限制
1. **GitHub API限制**: 即使使用Token，搜索API仍有速率限制
2. **数据完整性**: 仅获取元数据，缺少SKILL.md的详细技能描述
3. **分类系统**: 暂未实现智能分类映射，所有技能分类为"其他"

### 业务限制
1. **手动审核**: 爬取的技能需要管理员审核才能上架
2. **价格设置**: 所有爬取技能默认为免费，需手动设置价格
3. **质量控制**: 缺乏技能质量评估机制

## 未来扩展

### 短期优化（1-2周）
1. **分类映射**: 实现仓库语言/主题到技能分类的自动映射
2. **标签系统**: 集成标签创建和关联逻辑
3. **质量过滤**: 基于stars、forks、更新频率等指标过滤低质量仓库

### 中期增强（1-2月）
1. **多数据源**: 支持SkillsMP等第三方平台爬取
2. **AI增强**: 使用AI自动生成技能描述和标签
3. **实时同步**: 支持Webhook实时更新

### 长期规划（3-6月）
1. **分布式爬虫**: 支持多节点并行爬取
2. **智能推荐**: 基于用户行为推荐相关技能
3. **生态集成**: 与GitHub Marketplace等平台集成

## 部署说明

### 环境准备
1. 配置GitHub Personal Access Token
2. 设置数据库连接参数
3. 配置Redis缓存（如启用）

### 启动流程
1. 数据库迁移（自动或手动）
2. 启动后端服务
3. 初始化定时任务
4. 验证首次同步

### 健康检查
1. 监控`/health`端点
2. 检查同步日志
3. 验证技能数据更新

## 故障排除

### 常见问题

#### 1. 同步失败
- 检查GitHub Token有效性
- 验证网络连接和代理设置
- 查看API速率限制状态

#### 2. 数据不完整
- 确认主题配置正确性
- 检查分页参数设置
- 验证数据库连接

#### 3. 性能问题
- 调整分页大小和最大页数
- 优化同步间隔
- 考虑启用缓存

### 日志分析
- 错误级别日志包含详细堆栈信息
- 警告级别日志提示潜在问题
- 信息级别日志记录关键操作步骤

## 总结

GitHub爬虫系统实现了从GitHub自动同步技能数据的基础功能。系统采用模块化设计，支持灵活的配置和扩展。当前版本专注于稳定性和基本功能，为后续的数据增强和智能化处理奠定了基础。

**核心价值**: 自动化数据采集，减少手动录入工作量，确保技能数据的时效性和多样性。

**下一步**: 完善测试覆盖，优化分类和标签系统，集成到完整的技能审核和上架流程。